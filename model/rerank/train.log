nohup: ignoring input2023-03-28 01:47:44,874 - modelscope - INFO - PyTorch version 1.11.0+cu113 Found.2023-03-28 01:47:44,875 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer2023-03-28 01:47:44,900 - modelscope - INFO - Loading done! Current index file version is 1.3.0, with md5 b4991301c2d8ad6097ce4efc8f8e0df3 and a total number of 746 components indexed2023-03-28 01:47:46,352 - modelscope - INFO - No subset_name specified, defaulting to the defaultUsing custom data configuration DAMO_ConvAI-1f8a2fa35c0eebf2Found cached dataset vi_doc2_bot_rerank (/root/.cache/modelscope/hub/datasets/DAMO_ConvAI/ViDoc2BotRerank/master/meta/modelscope___dataset_builder/DAMO_ConvAI-1f8a2fa35c0eebf2/master/train)Model pretrain is False  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 490.56it/s]2023-03-28 01:47:47,609 - modelscope - INFO - No subset_name specified, defaulting to the defaultUsing custom data configuration DAMO_ConvAI-ea63db25dfc98074Found cached dataset fr_doc2_bot_rerank (/root/.cache/modelscope/hub/datasets/DAMO_ConvAI/FrDoc2BotRerank/master/meta/modelscope___dataset_builder/DAMO_ConvAI-ea63db25dfc98074/master/train)  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 639.86it/s]  0%|          | 0/100 00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 12048.10it/s]2023-03-28 01:47:49,342 - modelscope - INFO - train_dataset range: 50-3510&&3560-6956 ; evaluate_dataset range: 0-50&&3510-35602023-03-28 01:47:49,347 - modelscope - INFO - initialize model from ../XLM_largeSome weights of the model checkpoint at ../XLM_large were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at ../XLM_large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.2023-03-28 01:48:04,442 - modelscope - INFO - gathered positive pids for 6856 instances2023-03-28 01:48:06,191 - modelscope - INFO - ***** Running training *****2023-03-28 01:48:06,192 - modelscope - INFO -   Instantaneous batch size per GPU = 12023-03-28 01:48:06,192 - modelscope - INFO -   Total train batch size (w. parallel, distributed & accumulation) = 322023-03-28 01:48:06,192 - modelscope - INFO -   Gradient Accumulation steps = 322023-03-28 01:48:06,192 - modelscope - INFO -   Total optimization steps = 53562023-03-28 01:48:06,192 - modelscope - INFO -   Num Epochs = 252023-03-28 01:50:07,191 - modelscope - INFO - loss point 1 = 2.95360317421655652023-03-28 01:52:08,883 - modelscope - INFO - loss point 2 = 2.27870402631359072023-03-28 01:53:06,275 - modelscope - INFO - ==========================================2023-03-28 01:53:06,276 - modelscope - INFO - loss = 2.1341769855209134/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.  warnings.warn("To get the last learning rate computed by the scheduler, "2023-03-28 01:53:06,276 - modelscope - INFO - 5.674932207998683 instances per second; 1703 total (1.9802091112770724e-05 learn rate)2023-03-28 01:54:08,993 - modelscope - INFO - loss point 3 = 1.76092395587856452023-03-28 01:56:09,404 - modelscope - INFO - loss point 4 = 1.44740309035746242023-03-28 01:58:06,612 - modelscope - INFO - ==========================================2023-03-28 01:58:06,613 - modelscope - INFO - loss = 1.62037614640103042023-03-28 01:58:06,613 - modelscope - INFO - 5.669288160033918 instances per second; 3404 total (1.960418222554145e-05 learn rate)2023-03-28 01:58:09,842 - modelscope - INFO - loss point 5 = 1.26436670743535952023-03-28 02:00:12,153 - modelscope - INFO - loss point 6 = 1.08845817036848972023-03-28 02:02:12,822 - modelscope - INFO - loss point 7 = 0.99368116132965272023-03-28 02:03:06,885 - modelscope - INFO - ==========================================2023-03-28 02:03:06,886 - modelscope - INFO - loss = 1.38370568381605462023-03-28 02:03:06,886 - modelscope - INFO - 5.6666928776605525 instances per second; 5104 total (1.9406273338312173e-05 learn rate)2023-03-28 02:04:13,799 - modelscope - INFO - loss point 8 = 0.93909450138665282023-03-28 02:06:16,337 - modelscope - INFO - loss point 9 = 0.87535890242128232023-03-28 02:08:07,302 - modelscope - INFO - ==========================================2023-03-28 02:08:07,302 - modelscope - INFO - loss = 1.24515503388350112023-03-28 02:08:07,302 - modelscope - INFO - 5.648073885154612 instances per second; 6784 total (1.92083644510829e-05 learn rate)2023-03-28 02:08:18,102 - modelscope - INFO - loss point 10 = 0.83803257067907232023-03-28 02:08:19,032 - modelscope - INFO - epoch: 0 	 total_loss: 1.2411022792659387 	 2023-03-28 02:08:26,670 - modelscope - INFO - {'R@1': 0.91, 'R@2': 0.95, 'R@3': 0.95, 'R@5': 0.97}2023-03-28 02:08:26,673 - modelscope - INFO - meters is {'R@1': 0.91}2023-03-28 02:08:26,673 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328/best_model.bin2023-03-28 02:08:29,870 - modelscope - INFO - epoch 0 obtain max score: 0.9100, saving model to /root/autodl-tmp/output_rerank_choose_0328/best_model.bin2023-03-28 02:10:28,384 - modelscope - INFO - loss point 11 = 0.74089561550503852023-03-28 02:12:29,691 - modelscope - INFO - loss point 12 = 0.73320965241140782023-03-28 02:13:08,107 - modelscope - INFO - ==========================================2023-03-28 02:13:08,108 - modelscope - INFO - loss = 1.1382057711560272023-03-28 02:13:08,108 - modelscope - INFO - 5.614135190699445 instances per second; 8432 total (1.9017923823749068e-05 learn rate)2023-03-28 02:14:33,525 - modelscope - INFO - loss point 13 = 0.69411022493512432023-03-28 02:16:33,108 - modelscope - INFO - loss point 14 = 0.653322979826042023-03-28 02:18:10,732 - modelscope - INFO - ==========================================2023-03-28 02:18:10,732 - modelscope - INFO - loss = 1.04621256269892632023-03-28 02:18:10,732 - modelscope - INFO - 5.62135242112728 instances per second; 10144 total (1.881628080657207e-05 learn rate)2023-03-28 02:18:33,947 - modelscope - INFO - loss point 15 = 0.61047904296448052023-03-28 02:20:36,117 - modelscope - INFO - loss point 16 = 0.59638293264413372023-03-28 02:22:37,220 - modelscope - INFO - loss point 17 = 0.60276725461422182023-03-28 02:23:20,751 - modelscope - INFO - ==========================================2023-03-28 02:23:20,752 - modelscope - INFO - loss = 0.97777527707921062023-03-28 02:23:20,752 - modelscope - INFO - 5.629521016986462 instances per second; 11904 total (1.861090365944735e-05 learn rate)2023-03-28 02:24:37,242 - modelscope - INFO - loss point 18 = 0.60443512895280272023-03-28 02:26:36,559 - modelscope - INFO - loss point 19 = 0.64729355559734942023-03-28 02:28:28,131 - modelscope - INFO - ==========================================2023-03-28 02:28:28,132 - modelscope - INFO - loss = 0.91703295529636312023-03-28 02:28:28,132 - modelscope - INFO - 5.6285289497152196 instances per second; 13632 total (1.8409260642270353e-05 learn rate)2023-03-28 02:28:40,004 - modelscope - INFO - loss point 20 = 0.61362267144888082023-03-28 02:28:42,313 - modelscope - INFO - epoch: 1 	 total_loss: 0.9338542245000043 	 2023-03-28 02:28:49,918 - modelscope - INFO - {'R@1': 0.89, 'R@2': 0.96, 'R@3': 0.96, 'R@5': 0.98}2023-03-28 02:28:49,920 - modelscope - INFO - meters is {'R@1': 0.89}2023-03-28 02:30:46,974 - modelscope - INFO - loss point 21 = 0.53349705837037812023-03-28 02:32:48,380 - modelscope - INFO - loss point 22 = 0.447685997436242932023-03-28 02:33:28,683 - modelscope - INFO - ==========================================2023-03-28 02:33:28,683 - modelscope - INFO - loss = 0.84167235799208312023-03-28 02:33:28,684 - modelscope - INFO - 5.618367503475568 instances per second; 15296 total (1.82150858849888e-05 learn rate)2023-03-28 02:34:48,607 - modelscope - INFO - loss point 23 = 0.413024441419773462023-03-28 02:36:49,497 - modelscope - INFO - loss point 24 = 0.435843498401812862023-03-28 02:38:32,937 - modelscope - INFO - ==========================================2023-03-28 02:38:32,938 - modelscope - INFO - loss = 0.7773316873268822023-03-28 02:38:32,938 - modelscope - INFO - 5.624508955149644 instances per second; 17024 total (1.80134428678118e-05 learn rate)2023-03-28 02:38:50,469 - modelscope - INFO - loss point 25 = 0.43430316753696852023-03-28 02:40:51,821 - modelscope - INFO - loss point 26 = 0.40660941881587612023-03-28 02:42:54,947 - modelscope - INFO - loss point 27 = 0.398475974137937952023-03-28 02:43:41,551 - modelscope - INFO - ==========================================2023-03-28 02:43:41,551 - modelscope - INFO - loss = 0.71703409006436982023-03-28 02:43:41,551 - modelscope - INFO - 5.622171033208209 instances per second; 18752 total (1.7811799850634804e-05 learn rate)2023-03-28 02:44:57,739 - modelscope - INFO - loss point 28 = 0.436526256832305452023-03-28 02:46:58,934 - modelscope - INFO - loss point 29 = 0.43202210418335522023-03-28 02:48:48,017 - modelscope - INFO - ==========================================2023-03-28 02:48:48,018 - modelscope - INFO - loss = 0.66607887414229942023-03-28 02:48:48,018 - modelscope - INFO - 5.623541690133457 instances per second; 20480 total (1.7610156833457807e-05 learn rate)2023-03-28 02:48:59,774 - modelscope - INFO - loss point 30 = 0.379406588337072362023-03-28 02:49:02,922 - modelscope - INFO - epoch: 2 	 total_loss: 0.7593738957476794 	 2023-03-28 02:49:10,500 - modelscope - INFO - {'R@1': 0.9, 'R@2': 0.94, 'R@3': 0.97, 'R@5': 0.98}2023-03-28 02:49:10,502 - modelscope - INFO - meters is {'R@1': 0.9}2023-03-28 02:51:09,557 - modelscope - INFO - loss point 31 = 0.30676252047239642023-03-28 02:53:11,185 - modelscope - INFO - loss point 32 = 0.29308815267387352023-03-28 02:53:49,557 - modelscope - INFO - ==========================================2023-03-28 02:53:49,557 - modelscope - INFO - loss = 0.60612546731255872023-03-28 02:53:49,557 - modelscope - INFO - 5.6154980408030175 instances per second; 22144 total (1.7415982076176253e-05 learn rate)2023-03-28 02:55:11,558 - modelscope - INFO - loss point 33 = 0.29144360872266622023-03-28 02:57:13,409 - modelscope - INFO - loss point 34 = 0.26944759687821572023-03-28 02:58:57,518 - modelscope - INFO - ==========================================2023-03-28 02:58:57,518 - modelscope - INFO - loss = 0.5544340482268762023-03-28 02:58:57,518 - modelscope - INFO - 5.615179466908964 instances per second; 23872 total (1.7214339058999255e-05 learn rate)2023-03-28 02:59:16,305 - modelscope - INFO - loss point 35 = 0.286605892244653442023-03-28 03:01:16,470 - modelscope - INFO - loss point 36 = 0.306185686145628472023-03-28 03:03:16,703 - modelscope - INFO - loss point 37 = 0.257860217542273342023-03-28 03:04:01,889 - modelscope - INFO - ==========================================2023-03-28 03:04:01,889 - modelscope - INFO - loss = 0.50682939964367612023-03-28 03:04:01,889 - modelscope - INFO - 5.619328599349805 instances per second; 25600 total (1.7012696041822255e-05 learn rate)2023-03-28 03:05:16,252 - modelscope - INFO - loss point 38 = 0.2550579828330962023-03-28 03:07:16,159 - modelscope - INFO - loss point 39 = 0.29981859409460762023-03-28 03:09:06,069 - modelscope - INFO - ==========================================2023-03-28 03:09:06,070 - modelscope - INFO - loss = 0.47254125787306642023-03-28 03:09:06,070 - modelscope - INFO - 5.623178153555921 instances per second; 27328 total (1.6811053024645258e-05 learn rate)2023-03-28 03:09:19,091 - modelscope - INFO - loss point 40 = 0.281285037884164652023-03-28 03:09:23,464 - modelscope - INFO - epoch: 3 	 total_loss: 0.6379976492148336 	 2023-03-28 03:09:31,045 - modelscope - INFO - {'R@1': 0.86, 'R@2': 0.93, 'R@3': 0.96, 'R@5': 0.99}2023-03-28 03:09:31,048 - modelscope - INFO - meters is {'R@1': 0.86}2023-03-28 03:11:28,083 - modelscope - INFO - loss point 41 = 0.233762741944177682023-03-28 03:13:28,164 - modelscope - INFO - loss point 42 = 0.19616370574960742023-03-28 03:14:06,936 - modelscope - INFO - ==========================================2023-03-28 03:14:06,936 - modelscope - INFO - loss = 0.4281531030747832023-03-28 03:14:06,936 - modelscope - INFO - 5.617786238105646 instances per second; 28992 total (1.6616878267363707e-05 learn rate)2023-03-28 03:15:28,778 - modelscope - INFO - loss point 43 = 0.19601178124671382023-03-28 03:17:29,873 - modelscope - INFO - loss point 44 = 0.169260586932577122023-03-28 03:19:14,141 - modelscope - INFO - ==========================================2023-03-28 03:19:14,142 - modelscope - INFO - loss = 0.38690774884013542023-03-28 03:19:14,142 - modelscope - INFO - 5.618186022926329 instances per second; 30720 total (1.6415235250186706e-05 learn rate)2023-03-28 03:19:32,500 - modelscope - INFO - loss point 45 = 0.174604593225115182023-03-28 03:21:33,002 - modelscope - INFO - loss point 46 = 0.191934137051747422023-03-28 03:23:33,719 - modelscope - INFO - loss point 47 = 0.194867834782037872023-03-28 03:24:17,143 - modelscope - INFO - ==========================================2023-03-28 03:24:17,144 - modelscope - INFO - loss = 0.357324504576503942023-03-28 03:24:17,144 - modelscope - INFO - 5.622635484306005 instances per second; 32448 total (1.621359223300971e-05 learn rate)2023-03-28 03:25:31,897 - modelscope - INFO - loss point 48 = 0.206579554775309322023-03-28 03:27:37,279 - modelscope - INFO - loss point 49 = 0.219327305547379172023-03-28 03:29:25,745 - modelscope - INFO - ==========================================2023-03-28 03:29:25,745 - modelscope - INFO - loss = 0.33391185760425022023-03-28 03:29:25,745 - modelscope - INFO - 5.621458992980534 instances per second; 34176 total (1.601194921583271e-05 learn rate)2023-03-28 03:29:38,417 - modelscope - INFO - loss point 50 = 0.186474120369926832023-03-28 03:29:43,811 - modelscope - INFO - epoch: 4 	 total_loss: 0.5478306049255339 	 2023-03-28 03:29:51,402 - modelscope - INFO - {'R@1': 0.92, 'R@2': 0.96, 'R@3': 0.96, 'R@5': 0.99}2023-03-28 03:29:51,405 - modelscope - INFO - meters is {'R@1': 0.92}2023-03-28 03:29:51,406 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328/best_model.bin2023-03-28 03:29:56,425 - modelscope - INFO - epoch 4 obtain max score: 0.9200, saving model to /root/autodl-tmp/output_rerank_choose_0328/best_model.bin2023-03-28 03:31:52,180 - modelscope - INFO - loss point 51 = 0.1712842774860292023-03-28 03:33:54,385 - modelscope - INFO - loss point 52 = 0.142236871122431142023-03-28 03:34:33,160 - modelscope - INFO - ==========================================2023-03-28 03:34:33,160 - modelscope - INFO - loss = 0.302707391837652942023-03-28 03:34:33,160 - modelscope - INFO - 5.611419316428637 instances per second; 35840 total (1.5817774458551157e-05 learn rate)2023-03-28 03:35:55,822 - modelscope - INFO - loss point 53 = 0.150890001632013552023-03-28 03:37:55,863 - modelscope - INFO - loss point 54 = 0.133329840015948282023-03-28 03:39:35,734 - modelscope - INFO - ==========================================2023-03-28 03:39:35,734 - modelscope - INFO - loss = 0.27632278744599772023-03-28 03:39:35,734 - modelscope - INFO - 5.615923442641315 instances per second; 37568 total (1.561613144137416e-05 learn rate)2023-03-28 03:39:54,820 - modelscope - INFO - loss point 55 = 0.153811514775564432023-03-28 03:41:57,932 - modelscope - INFO - loss point 56 = 0.155232817826396032023-03-28 03:43:59,809 - modelscope - INFO - loss point 57 = 0.14768691899147562023-03-28 03:44:44,260 - modelscope - INFO - ==========================================2023-03-28 03:44:44,260 - modelscope - INFO - loss = 0.256005208678485252023-03-28 03:44:44,260 - modelscope - INFO - 5.615257762061024 instances per second; 39296 total (1.5414488424197163e-05 learn rate)2023-03-28 03:46:00,318 - modelscope - INFO - loss point 58 = 0.141145460262327082023-03-28 03:48:00,514 - modelscope - INFO - loss point 59 = 0.139548514611977312023-03-28 03:49:48,330 - modelscope - INFO - ==========================================2023-03-28 03:49:48,330 - modelscope - INFO - loss = 0.237794445416050442023-03-28 03:49:48,330 - modelscope - INFO - 5.618074825371606 instances per second; 41024 total (1.5212845407020164e-05 learn rate)2023-03-28 03:50:02,383 - modelscope - INFO - loss point 60 = 0.13447172969016612023-03-28 03:50:09,360 - modelscope - INFO - epoch: 5 	 total_loss: 0.47973314419656565 	 2023-03-28 03:50:16,970 - modelscope - INFO - {'R@1': 0.89, 'R@2': 0.95, 'R@3': 0.99, 'R@5': 1.0}2023-03-28 03:50:16,973 - modelscope - INFO - meters is {'R@1': 0.89}2023-03-28 03:52:15,187 - modelscope - INFO - loss point 61 = 0.123693092772181892023-03-28 03:54:17,111 - modelscope - INFO - loss point 62 = 0.117382849498308742023-03-28 03:54:55,582 - modelscope - INFO - ==========================================2023-03-28 03:54:55,583 - modelscope - INFO - loss = 0.21807593739275642023-03-28 03:54:55,583 - modelscope - INFO - 5.609904917095441 instances per second; 42688 total (1.5018670649738611e-05 learn rate)2023-03-28 03:56:18,115 - modelscope - INFO - loss point 63 = 0.086778901477701622023-03-28 03:58:18,705 - modelscope - INFO - loss point 64 = 0.090498331234253732023-03-28 04:00:01,561 - modelscope - INFO - ==========================================2023-03-28 04:00:01,561 - modelscope - INFO - loss = 0.195109788472695142023-03-28 04:00:01,561 - modelscope - INFO - 5.61135651689377 instances per second; 44416 total (1.4817027632561614e-05 learn rate)2023-03-28 04:00:19,535 - modelscope - INFO - loss point 65 = 0.093775714080287132023-03-28 04:02:21,805 - modelscope - INFO - loss point 66 = 0.100892730866383412023-03-28 04:04:23,371 - modelscope - INFO - loss point 67 = 0.11701604885317362023-03-28 04:05:07,079 - modelscope - INFO - ==========================================2023-03-28 04:05:07,079 - modelscope - INFO - loss = 0.184146477633958082023-03-28 04:05:07,079 - modelscope - INFO - 5.613014375861311 instances per second; 46144 total (1.4615384615384615e-05 learn rate)2023-03-28 04:06:22,538 - modelscope - INFO - loss point 68 = 0.103356541849372922023-03-28 04:08:22,862 - modelscope - INFO - loss point 69 = 0.108998529556598442023-03-28 04:10:10,348 - modelscope - INFO - ==========================================2023-03-28 04:10:10,349 - modelscope - INFO - loss = 0.171640479068608022023-03-28 04:10:10,349 - modelscope - INFO - 5.616034468316643 instances per second; 47872 total (1.4413741598207618e-05 learn rate)2023-03-28 04:10:23,249 - modelscope - INFO - loss point 70 = 0.111866006859477912023-03-28 04:10:30,207 - modelscope - INFO - epoch: 6 	 total_loss: 0.4260688389801906 	 2023-03-28 04:10:37,861 - modelscope - INFO - {'R@1': 0.89, 'R@2': 0.94, 'R@3': 0.99, 'R@5': 0.99}2023-03-28 04:10:37,863 - modelscope - INFO - meters is {'R@1': 0.89}2023-03-28 04:12:31,216 - modelscope - INFO - loss point 71 = 0.090804695802437182023-03-28 04:14:32,400 - modelscope - INFO - loss point 72 = 0.076803908745656712023-03-28 04:15:12,020 - modelscope - INFO - ==========================================2023-03-28 04:15:12,020 - modelscope - INFO - loss = 0.155920632341959332023-03-28 04:15:12,020 - modelscope - INFO - 5.612612961806205 instances per second; 49536 total (1.4219566840926064e-05 learn rate)2023-03-28 04:16:34,362 - modelscope - INFO - loss point 73 = 0.085570102841013392023-03-28 04:18:35,753 - modelscope - INFO - loss point 74 = 0.082893476281995852023-03-28 04:20:18,243 - modelscope - INFO - ==========================================2023-03-28 04:20:18,243 - modelscope - INFO - loss = 0.1447781727212962023-03-28 04:20:18,243 - modelscope - INFO - 5.613630303355742 instances per second; 51264 total (1.4017923823749067e-05 learn rate)2023-03-28 04:20:38,559 - modelscope - INFO - loss point 75 = 0.07843362922328992023-03-28 04:22:39,465 - modelscope - INFO - loss point 76 = 0.076875623607344552023-03-28 04:24:41,285 - modelscope - INFO - loss point 77 = 0.08520415065435112023-03-28 04:25:26,265 - modelscope - INFO - ==========================================2023-03-28 04:25:26,265 - modelscope - INFO - loss = 0.135508210988656872023-03-28 04:25:26,265 - modelscope - INFO - 5.61351151941997 instances per second; 52992 total (1.381628080657207e-05 learn rate)2023-03-28 04:26:45,548 - modelscope - INFO - loss point 78 = 0.094343250656415792023-03-28 04:28:45,238 - modelscope - INFO - loss point 79 = 0.098409685408640652023-03-28 04:30:31,000 - modelscope - INFO - ==========================================2023-03-28 04:30:31,000 - modelscope - INFO - loss = 0.12865224969823572023-03-28 04:30:31,000 - modelscope - INFO - 5.6152934834290935 instances per second; 54720 total (1.361463778939507e-05 learn rate)2023-03-28 04:30:44,496 - modelscope - INFO - loss point 80 = 0.087601625626222472023-03-28 04:30:53,309 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328/_72023-03-28 04:30:56,352 - modelscope - INFO - epoch: 7 	 total_loss: 0.38305619244346195 	 2023-03-28 04:31:04,017 - modelscope - INFO - {'R@1': 0.9, 'R@2': 0.95, 'R@3': 0.97, 'R@5': 0.99}2023-03-28 04:31:04,020 - modelscope - INFO - meters is {'R@1': 0.9}2023-03-28 04:32:58,539 - modelscope - INFO - loss point 81 = 0.074452714206647942023-03-28 04:35:01,661 - modelscope - INFO - loss point 82 = 0.073572402668239062023-03-28 04:35:38,444 - modelscope - INFO - ==========================================2023-03-28 04:35:38,444 - modelscope - INFO - loss = 0.118025444303316552023-03-28 04:35:38,445 - modelscope - INFO - 5.609086887325671 instances per second; 56384 total (1.3420463032113518e-05 learn rate)2023-03-28 04:37:02,019 - modelscope - INFO - loss point 83 = 0.063756667734840892023-03-28 04:39:03,658 - modelscope - INFO - loss point 84 = 0.065073295556216712023-03-28 04:40:42,564 - modelscope - INFO - ==========================================2023-03-28 04:40:42,564 - modelscope - INFO - loss = 0.107635193190914442023-03-28 04:40:42,564 - modelscope - INFO - 5.611227281028451 instances per second; 58112 total (1.3218820014936519e-05 learn rate)2023-03-28 04:41:03,375 - modelscope - INFO - loss point 85 = 0.054783073958320542023-03-28 04:43:05,436 - modelscope - INFO - loss point 86 = 0.055249257186018812023-03-28 04:45:07,787 - modelscope - INFO - loss point 87 = 0.070954234781679552023-03-28 04:45:50,745 - modelscope - INFO - ==========================================2023-03-28 04:45:50,746 - modelscope - INFO - loss = 0.102699564912610422023-03-28 04:45:50,746 - modelscope - INFO - 5.611107637935888 instances per second; 59840 total (1.3017176997759523e-05 learn rate)2023-03-28 04:47:08,762 - modelscope - INFO - loss point 88 = 0.068279684573466172023-03-28 04:49:09,589 - modelscope - INFO - loss point 89 = 0.066378875872927462023-03-28 04:50:58,285 - modelscope - INFO - ==========================================2023-03-28 04:50:58,286 - modelscope - INFO - loss = 0.095644118775142212023-03-28 04:50:58,286 - modelscope - INFO - 5.611322607967722 instances per second; 61568 total (1.2815533980582526e-05 learn rate)2023-03-28 04:51:12,435 - modelscope - INFO - loss point 90 = 0.059582187432997562023-03-28 04:51:21,871 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328/_82023-03-28 04:51:24,969 - modelscope - INFO - epoch: 8 	 total_loss: 0.3474185957006376 	 2023-03-28 04:51:32,861 - modelscope - INFO - {'R@1': 0.87, 'R@2': 0.94, 'R@3': 0.98, 'R@5': 0.99}2023-03-28 04:51:32,863 - modelscope - INFO - meters is {'R@1': 0.87}2023-03-28 04:53:25,265 - modelscope - INFO - loss point 91 = 0.0534605881087564452023-03-28 04:55:28,977 - modelscope - INFO - loss point 92 = 0.042007090535587482023-03-28 04:56:06,621 - modelscope - INFO - ==========================================2023-03-28 04:56:06,622 - modelscope - INFO - loss = 0.086896410655438822023-03-28 04:56:06,622 - modelscope - INFO - 5.605456537149731 instances per second; 63232 total (1.2621359223300974e-05 learn rate)2023-03-28 04:57:28,599 - modelscope - INFO - loss point 93 = 0.036910202539574422023-03-28 04:59:29,426 - modelscope - INFO - loss point 94 = 0.0492143340257088152023-03-28 05:01:10,916 - modelscope - INFO - ==========================================2023-03-28 05:01:10,916 - modelscope - INFO - loss = 0.082403592627551382023-03-28 05:01:10,916 - modelscope - INFO - 5.607380802268816 instances per second; 64960 total (1.2419716206123975e-05 learn rate)2023-03-28 05:01:31,362 - modelscope - INFO - loss point 95 = 0.057164622265455592023-03-28 05:03:32,639 - modelscope - INFO - loss point 96 = 0.05939202949354792023-03-28 05:05:31,917 - modelscope - INFO - loss point 97 = 0.067649017318103442023-03-28 05:06:16,390 - modelscope - INFO - ==========================================2023-03-28 05:06:16,390 - modelscope - INFO - loss = 0.079821552147620672023-03-28 05:06:16,391 - modelscope - INFO - 5.608649681126402 instances per second; 66688 total (1.2218073188946977e-05 learn rate)2023-03-28 05:07:35,866 - modelscope - INFO - loss point 98 = 0.055542921531992122023-03-28 05:09:37,565 - modelscope - INFO - loss point 99 = 0.04125770465380132023-03-28 05:11:24,506 - modelscope - INFO - ==========================================2023-03-28 05:11:24,506 - modelscope - INFO - loss = 0.07408529703866022023-03-28 05:11:24,507 - modelscope - INFO - 5.608640258507047 instances per second; 68416 total (1.201643017176998e-05 learn rate)2023-03-28 05:11:39,977 - modelscope - INFO - loss point 100 = 0.055545992177391682023-03-28 05:11:50,872 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328/_92023-03-28 05:11:53,855 - modelscope - INFO - epoch: 9 	 total_loss: 0.3177820239221327 	 2023-03-28 05:12:01,548 - modelscope - INFO - {'R@1': 0.89, 'R@2': 0.94, 'R@3': 0.98, 'R@5': 0.99}2023-03-28 05:12:01,549 - modelscope - INFO - meters is {'R@1': 0.89}2023-03-28 05:13:53,921 - modelscope - INFO - loss point 101 = 0.05231743089102532023-03-28 05:15:58,050 - modelscope - INFO - loss point 102 = 0.053372393398701012023-03-28 05:16:34,122 - modelscope - INFO - ==========================================2023-03-28 05:16:34,123 - modelscope - INFO - loss = 0.070247750081607152023-03-28 05:16:34,123 - modelscope - INFO - 5.602841855375091 instances per second; 70080 total (1.1822255414488426e-05 learn rate)2023-03-28 05:17:59,717 - modelscope - INFO - loss point 103 = 0.037743210015854332023-03-28 05:20:02,313 - modelscope - INFO - loss point 104 = 0.053226319983947652023-03-28 05:21:42,740 - modelscope - INFO - ==========================================2023-03-28 05:21:42,741 - modelscope - INFO - loss = 0.065861371221802082023-03-28 05:21:42,741 - modelscope - INFO - 5.602753082302939 instances per second; 71808 total (1.1620612397311429e-05 learn rate)2023-03-28 05:22:03,401 - modelscope - INFO - loss point 105 = 0.042499831730200932023-03-28 05:24:02,414 - modelscope - INFO - loss point 106 = 0.030399670798592952023-03-28 05:26:03,754 - modelscope - INFO - loss point 107 = 0.034296526938891832023-03-28 05:26:45,881 - modelscope - INFO - ==========================================2023-03-28 05:26:45,881 - modelscope - INFO - loss = 0.061610759274413162023-03-28 05:26:45,882 - modelscope - INFO - 5.605007501118585 instances per second; 73536 total (1.141896938013443e-05 learn rate)2023-03-28 05:28:05,824 - modelscope - INFO - loss point 108 = 0.043819223938467712023-03-28 05:30:07,888 - modelscope - INFO - loss point 109 = 0.0386551054391659772023-03-28 05:31:51,696 - modelscope - INFO - ==========================================2023-03-28 05:31:51,696 - modelscope - INFO - loss = 0.057591772247358492023-03-28 05:31:51,696 - modelscope - INFO - 5.60604319965383 instances per second; 75264 total (1.1217326362957433e-05 learn rate)2023-03-28 05:32:07,254 - modelscope - INFO - loss point 110 = 0.0347171777802617042023-03-28 05:32:19,062 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328/_102023-03-28 05:32:22,160 - modelscope - INFO - epoch: 10 	 total_loss: 0.2925957517705012 	 2023-03-28 05:32:29,844 - modelscope - INFO - {'R@1': 0.87, 'R@2': 0.94, 'R@3': 0.97, 'R@5': 0.99}2023-03-28 05:32:29,845 - modelscope - INFO - meters is {'R@1': 0.87}2023-03-28 05:34:19,686 - modelscope - INFO - loss point 111 = 0.0262509396158496642023-03-28 05:36:23,426 - modelscope - INFO - loss point 112 = 0.024119421412100542023-03-28 05:37:00,813 - modelscope - INFO - ==========================================2023-03-28 05:37:00,813 - modelscope - INFO - loss = 0.0521798733745160662023-03-28 05:37:00,813 - modelscope - INFO - 5.601025027965437 instances per second; 76928 total (1.1023151605675878e-05 learn rate)2023-03-28 05:38:24,511 - modelscope - INFO - loss point 113 = 0.020415936090625582023-03-28 05:40:26,023 - modelscope - INFO - loss point 114 = 0.0381353582976409062023-03-28 05:42:04,874 - modelscope - INFO - ==========================================2023-03-28 05:42:04,874 - modelscope - INFO - loss = 0.050415634420739152023-03-28 05:42:04,874 - modelscope - INFO - 5.6028022337218335 instances per second; 78656 total (1.0821508588498881e-05 learn rate)2023-03-28 05:42:26,252 - modelscope - INFO - loss point 115 = 0.0370329280988338852023-03-28 05:44:26,321 - modelscope - INFO - loss point 116 = 0.039795490611632222023-03-28 05:46:29,490 - modelscope - INFO - loss point 117 = 0.040853227352158532023-03-28 05:47:13,080 - modelscope - INFO - ==========================================2023-03-28 05:47:13,080 - modelscope - INFO - loss = 0.048946600627072052023-03-28 05:47:13,081 - modelscope - INFO - 5.6028844138703455 instances per second; 80384 total (1.0619865571321884e-05 learn rate)2023-03-28 05:48:31,191 - modelscope - INFO - loss point 118 = 0.044293917297162392023-03-28 05:50:33,161 - modelscope - INFO - loss point 119 = 0.037814583463358442023-03-28 05:52:18,648 - modelscope - INFO - ==========================================2023-03-28 05:52:18,649 - modelscope - INFO - loss = 0.046822614204562782023-03-28 05:52:18,649 - modelscope - INFO - 5.603972065624673 instances per second; 82112 total (1.0418222554144885e-05 learn rate)2023-03-28 05:52:35,250 - modelscope - INFO - loss point 120 = 0.031502684362961682023-03-28 05:52:46,967 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328/_112023-03-28 05:52:50,269 - modelscope - INFO - epoch: 11 	 total_loss: 0.27113960535061693 	 2023-03-28 05:52:57,990 - modelscope - INFO - {'R@1': 0.9, 'R@2': 0.95, 'R@3': 0.97, 'R@5': 0.99}2023-03-28 05:52:57,993 - modelscope - INFO - meters is {'R@1': 0.9}2023-03-28 05:54:45,557 - modelscope - INFO - loss point 121 = 0.0225246789602862632023-03-28 05:56:46,356 - modelscope - INFO - loss point 122 = 0.02478966559392972023-03-28 05:57:22,051 - modelscope - INFO - ==========================================2023-03-28 05:57:22,051 - modelscope - INFO - loss = 0.042378889260631682023-03-28 05:57:22,051 - modelscope - INFO - 5.601547731966803 instances per second; 83776 total (1.0224047796863332e-05 learn rate)2023-03-28 05:58:48,065 - modelscope - INFO - loss point 123 = 0.0207212270781428382023-03-28 06:00:48,607 - modelscope - INFO - loss point 124 = 0.019782770478629122023-03-28 06:02:29,571 - modelscope - INFO - ==========================================2023-03-28 06:02:29,572 - modelscope - INFO - loss = 0.039826567670355462023-03-28 06:02:29,572 - modelscope - INFO - 5.601902102882562 instances per second; 85504 total (1.0022404779686335e-05 learn rate)2023-03-28 06:02:50,728 - modelscope - INFO - loss point 125 = 0.031355493304590472023-03-28 06:04:50,809 - modelscope - INFO - loss point 126 = 0.0346320436979355442023-03-28 06:06:54,082 - modelscope - INFO - loss point 127 = 0.032639166526174482023-03-28 06:07:36,062 - modelscope - INFO - ==========================================2023-03-28 06:07:36,062 - modelscope - INFO - loss = 0.040611268069818782023-03-28 06:07:36,062 - modelscope - INFO - 5.602613109274608 instances per second; 87232 total (9.820761762509336e-06 learn rate)2023-03-28 06:08:54,858 - modelscope - INFO - loss point 128 = 0.041116849561826632023-03-28 06:10:58,733 - modelscope - INFO - loss point 129 = 0.039919347624203582023-03-28 06:12:44,864 - modelscope - INFO - ==========================================2023-03-28 06:12:44,864 - modelscope - INFO - loss = 0.0398343321633377252023-03-28 06:12:44,864 - modelscope - INFO - 5.602480895181745 instances per second; 88960 total (9.619118745332339e-06 learn rate)2023-03-28 06:13:01,413 - modelscope - INFO - loss point 130 = 0.032543573835910632023-03-28 06:13:15,327 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328/_122023-03-28 06:13:18,612 - modelscope - INFO - epoch: 12 	 total_loss: 0.2526460426372901 	 2023-03-28 06:13:26,326 - modelscope - INFO - {'R@1': 0.87, 'R@2': 0.96, 'R@3': 0.98, 'R@5': 0.99}2023-03-28 06:13:26,329 - modelscope - INFO - meters is {'R@1': 0.87}2023-03-28 06:15:13,672 - modelscope - INFO - loss point 131 = 0.0257872042187695872023-03-28 06:17:16,249 - modelscope - INFO - loss point 132 = 0.0155288618559232332023-03-28 06:17:52,107 - modelscope - INFO - ==========================================2023-03-28 06:17:52,108 - modelscope - INFO - loss = 0.0357418376349554062023-03-28 06:17:52,108 - modelscope - INFO - 5.598939177390765 instances per second; 90624 total (9.424943988050785e-06 learn rate)2023-03-28 06:19:18,547 - modelscope - INFO - loss point 133 = 0.02842436780005192023-03-28 06:21:20,078 - modelscope - INFO - loss point 134 = 0.021901782121278462023-03-28 06:23:00,207 - modelscope - INFO - ==========================================2023-03-28 06:23:00,207 - modelscope - INFO - loss = 0.034806104228742542023-03-28 06:23:00,207 - modelscope - INFO - 5.599119227304301 instances per second; 92352 total (9.223300970873788e-06 learn rate)2023-03-28 06:23:20,655 - modelscope - INFO - loss point 135 = 0.0279190842872242382023-03-28 06:25:21,361 - modelscope - INFO - loss point 136 = 0.0234835656054580222023-03-28 06:27:20,067 - modelscope - INFO - loss point 137 = 0.0227320108080599672023-03-28 06:28:01,773 - modelscope - INFO - ==========================================2023-03-28 06:28:01,773 - modelscope - INFO - loss = 0.032729105998400722023-03-28 06:28:01,773 - modelscope - INFO - 5.601470936166511 instances per second; 94080 total (9.02165795369679e-06 learn rate)2023-03-28 06:29:21,841 - modelscope - INFO - loss point 138 = 0.019783670438888722023-03-28 06:31:25,855 - modelscope - INFO - loss point 139 = 0.020680095345505532023-03-28 06:33:09,888 - modelscope - INFO - ==========================================2023-03-28 06:33:09,888 - modelscope - INFO - loss = 0.0295052478407477962023-03-28 06:33:09,888 - modelscope - INFO - 5.601593856864513 instances per second; 95808 total (8.820014936519791e-06 learn rate)2023-03-28 06:33:26,939 - modelscope - INFO - loss point 140 = 0.0150393035664452332023-03-28 06:33:42,005 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328/_132023-03-28 06:33:45,097 - modelscope - INFO - epoch: 13 	 total_loss: 0.2360702646600502 	 2023-03-28 06:33:52,787 - modelscope - INFO - {'R@1': 0.9, 'R@2': 0.95, 'R@3': 0.99, 'R@5': 0.99}2023-03-28 06:33:52,789 - modelscope - INFO - meters is {'R@1': 0.9}2023-03-28 06:35:39,417 - modelscope - INFO - loss point 141 = 0.0179192879610971282023-03-28 06:37:39,451 - modelscope - INFO - loss point 142 = 0.0191439433150103272023-03-28 06:38:14,599 - modelscope - INFO - ==========================================2023-03-28 06:38:14,599 - modelscope - INFO - loss = 0.0282194530267408582023-03-28 06:38:14,599 - modelscope - INFO - 5.599131393624564 instances per second; 97472 total (8.625840179238239e-06 learn rate)2023-03-28 06:39:40,191 - modelscope - INFO - loss point 143 = 0.0126837485374344182023-03-28 06:41:40,388 - modelscope - INFO - loss point 144 = 0.0125281771367817772023-03-28 06:43:21,223 - modelscope - INFO - ==========================================2023-03-28 06:43:21,223 - modelscope - INFO - loss = 0.025147000347016892023-03-28 06:43:21,223 - modelscope - INFO - 5.59976200697165 instances per second; 99200 total (8.42419716206124e-06 learn rate)2023-03-28 06:43:44,130 - modelscope - INFO - loss point 145 = 0.0092360899538449752023-03-28 06:45:45,073 - modelscope - INFO - loss point 146 = 0.0202176309302142322023-03-28 06:47:47,377 - modelscope - INFO - loss point 147 = 0.020533284722013672023-03-28 06:48:28,241 - modelscope - INFO - ==========================================2023-03-28 06:48:28,241 - modelscope - INFO - loss = 0.0254317138595401662023-03-28 06:48:28,241 - modelscope - INFO - 5.600248792571668 instances per second; 100928 total (8.222554144884243e-06 learn rate)2023-03-28 06:49:48,006 - modelscope - INFO - loss point 148 = 0.0228750609224495332023-03-28 06:51:50,563 - modelscope - INFO - loss point 149 = 0.0272249217719717742023-03-28 06:53:36,272 - modelscope - INFO - ==========================================2023-03-28 06:53:36,272 - modelscope - INFO - loss = 0.0252999553650549442023-03-28 06:53:36,272 - modelscope - INFO - 5.600409570321811 instances per second; 102656 total (8.020911127707245e-06 learn rate)2023-03-28 06:53:52,629 - modelscope - INFO - loss point 150 = 0.0223479781450999472023-03-28 06:54:08,929 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328/_142023-03-28 06:54:12,159 - modelscope - INFO - epoch: 14 	 total_loss: 0.22161498270513194 	 2023-03-28 06:54:19,882 - modelscope - INFO - {'R@1': 0.92, 'R@2': 0.97, 'R@3': 0.98, 'R@5': 0.99}2023-03-28 06:54:19,884 - modelscope - INFO - meters is {'R@1': 0.92}2023-03-28 06:54:19,885 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328/best_model.bin2023-03-28 06:54:24,746 - modelscope - INFO - epoch 14 obtain max score: 0.9200, saving model to /root/autodl-tmp/output_rerank_choose_0328/best_model.bin2023-03-28 06:56:09,199 - modelscope - INFO - loss point 151 = 0.01821683286217182023-03-28 06:58:11,364 - modelscope - INFO - loss point 152 = 0.0151213777782683342023-03-28 06:58:47,628 - modelscope - INFO - ==========================================2023-03-28 06:58:47,629 - modelscope - INFO - loss = 0.022971693585943622023-03-28 06:58:47,629 - modelscope - INFO - 5.596132963920467 instances per second; 104320 total (7.826736370425691e-06 learn rate)2023-03-28 07:00:12,759 - modelscope - INFO - loss point 153 = 0.016770603456409992023-03-28 07:02:14,172 - modelscope - INFO - loss point 154 = 0.0111125581496491522023-03-28 07:03:51,397 - modelscope - INFO - ==========================================2023-03-28 07:03:51,397 - modelscope - INFO - loss = 0.0212968697065631442023-03-28 07:03:51,397 - modelscope - INFO - 5.597614705432739 instances per second; 106048 total (7.625093353248694e-06 learn rate)2023-03-28 07:04:14,340 - modelscope - INFO - loss point 155 = 0.0102417046854921152023-03-28 07:06:14,503 - modelscope - INFO - loss point 156 = 0.0229272283809188672023-03-28 07:08:16,660 - modelscope - INFO - loss point 157 = 0.0162561070144728282023-03-28 07:08:57,522 - modelscope - INFO - ==========================================2023-03-28 07:08:57,522 - modelscope - INFO - loss = 0.020734757307160382023-03-28 07:08:57,522 - modelscope - INFO - 5.59836417940419 instances per second; 107776 total (7.423450336071696e-06 learn rate)2023-03-28 07:10:19,183 - modelscope - INFO - loss point 158 = 0.0120207959374528022023-03-28 07:12:20,571 - modelscope - INFO - loss point 159 = 0.0102190670928716842023-03-28 07:14:04,347 - modelscope - INFO - ==========================================2023-03-28 07:14:04,347 - modelscope - INFO - loss = 0.0201499877626252142023-03-28 07:14:04,347 - modelscope - INFO - 5.5988899479282015 instances per second; 109504 total (7.221807318894698e-06 learn rate)2023-03-28 07:14:21,187 - modelscope - INFO - loss point 160 = 0.0177965060842208422023-03-28 07:14:38,282 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328/_152023-03-28 07:14:41,186 - modelscope - INFO - epoch: 15 	 total_loss: 0.20865740279133432 	 2023-03-28 07:14:48,817 - modelscope - INFO - {'R@1': 0.89, 'R@2': 0.93, 'R@3': 0.98, 'R@5': 0.99}2023-03-28 07:14:48,819 - modelscope - INFO - meters is {'R@1': 0.89}2023-03-28 07:16:35,027 - modelscope - INFO - loss point 161 = 0.0104675641718592152023-03-28 07:18:36,627 - modelscope - INFO - loss point 162 = 0.0136843564574873782023-03-28 07:19:12,200 - modelscope - INFO - ==========================================2023-03-28 07:19:12,200 - modelscope - INFO - loss = 0.018419541814281672023-03-28 07:19:12,201 - modelscope - INFO - 5.595887972697623 instances per second; 111168 total (7.027632561613144e-06 learn rate)2023-03-28 07:20:38,448 - modelscope - INFO - loss point 163 = 0.0075657404948424382023-03-28 07:22:39,967 - modelscope - INFO - loss point 164 = 0.00653463315411557942023-03-28 07:24:18,882 - modelscope - INFO - ==========================================2023-03-28 07:24:18,882 - modelscope - INFO - loss = 0.0164665271530600562023-03-28 07:24:18,882 - modelscope - INFO - 5.596475041707191 instances per second; 112896 total (6.825989544436147e-06 learn rate)2023-03-28 07:24:42,327 - modelscope - INFO - loss point 165 = 0.0127789607256039282023-03-28 07:26:41,283 - modelscope - INFO - loss point 166 = 0.0174621163443013822023-03-28 07:28:42,420 - modelscope - INFO - loss point 167 = 0.022333793721562712023-03-28 07:29:24,389 - modelscope - INFO - ==========================================2023-03-28 07:29:24,390 - modelscope - INFO - loss = 0.017421767908330362023-03-28 07:29:24,390 - modelscope - INFO - 5.597365514037588 instances per second; 114624 total (6.624346527259149e-06 learn rate)2023-03-28 07:30:45,038 - modelscope - INFO - loss point 168 = 0.019555431818996732023-03-28 07:32:45,465 - modelscope - INFO - loss point 169 = 0.0117153692743616722023-03-28 07:34:29,514 - modelscope - INFO - ==========================================2023-03-28 07:34:29,514 - modelscope - INFO - loss = 0.0168847978003976542023-03-28 07:34:29,515 - modelscope - INFO - 5.598332903242571 instances per second; 116352 total (6.422703510082151e-06 learn rate)2023-03-28 07:34:47,542 - modelscope - INFO - loss point 170 = 0.014150859139079342023-03-28 07:35:05,112 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328/_162023-03-28 07:35:08,598 - modelscope - INFO - epoch: 16 	 total_loss: 0.19714068479172794 	 2023-03-28 07:35:16,467 - modelscope - INFO - {'R@1': 0.9, 'R@2': 0.95, 'R@3': 0.98, 'R@5': 0.99}2023-03-28 07:35:16,470 - modelscope - INFO - meters is {'R@1': 0.9}2023-03-28 07:36:59,421 - modelscope - INFO - loss point 171 = 0.0138482645515662862023-03-28 07:39:01,437 - modelscope - INFO - loss point 172 = 0.0075949652197329612023-03-28 07:39:36,534 - modelscope - INFO - ==========================================2023-03-28 07:39:36,535 - modelscope - INFO - loss = 0.0152602953644313812023-03-28 07:39:36,535 - modelscope - INFO - 5.595734511699357 instances per second; 118016 total (6.228528752800598e-06 learn rate)2023-03-28 07:41:03,504 - modelscope - INFO - loss point 173 = 0.0071011058833254832023-03-28 07:43:06,510 - modelscope - INFO - loss point 174 = 0.0097333130214383172023-03-28 07:44:41,975 - modelscope - INFO - ==========================================2023-03-28 07:44:41,975 - modelscope - INFO - loss = 0.0144454845460842122023-03-28 07:44:41,975 - modelscope - INFO - 5.596614906054165 instances per second; 119744 total (6.0268857356235995e-06 learn rate)2023-03-28 07:45:05,151 - modelscope - INFO - loss point 175 = 0.0069058969966982252023-03-28 07:47:07,532 - modelscope - INFO - loss point 176 = 0.00364774996631892422023-03-28 07:49:07,591 - modelscope - INFO - loss point 177 = 0.0112446408082884522023-03-28 07:49:47,204 - modelscope - INFO - ==========================================2023-03-28 07:49:47,204 - modelscope - INFO - loss = 0.0135376110722928172023-03-28 07:49:47,204 - modelscope - INFO - 5.597525023910771 instances per second; 121472 total (5.825242718446602e-06 learn rate)2023-03-28 07:51:10,328 - modelscope - INFO - loss point 178 = 0.0088487800993409022023-03-28 07:53:15,507 - modelscope - INFO - loss point 179 = 0.0083058156776190662023-03-28 07:54:48,060 - modelscope - INFO - ==========================================2023-03-28 07:54:48,060 - modelscope - INFO - loss = 0.0127692819388813882023-03-28 07:54:48,060 - modelscope - INFO - 5.596613722572211 instances per second; 123136 total (5.631067961165049e-06 learn rate)2023-03-28 07:55:17,019 - modelscope - INFO - loss point 180 = 0.0079180290101705362023-03-28 07:55:35,808 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328/_172023-03-28 07:55:39,050 - modelscope - INFO - epoch: 17 	 total_loss: 0.18666338001342958 	 2023-03-28 07:55:46,759 - modelscope - INFO - {'R@1': 0.91, 'R@2': 0.97, 'R@3': 0.98, 'R@5': 0.99}2023-03-28 07:55:46,763 - modelscope - INFO - meters is {'R@1': 0.91}2023-03-28 07:57:29,143 - modelscope - INFO - loss point 181 = 0.0068232203464636232023-03-28 07:59:31,531 - modelscope - INFO - loss point 182 = 0.0092977523522285562023-03-28 07:59:54,878 - modelscope - INFO - ==========================================2023-03-28 07:59:54,879 - modelscope - INFO - loss = 0.0119029301154388222023-03-28 07:59:54,879 - modelscope - INFO - 5.594231532145149 instances per second; 124800 total (5.436893203883496e-06 learn rate)2023-03-28 08:01:30,783 - modelscope - INFO - loss point 183 = 0.0087581376833190522023-03-28 08:03:32,622 - modelscope - INFO - loss point 184 = 0.0066347021617977812023-03-28 08:04:58,897 - modelscope - INFO - ==========================================2023-03-28 08:04:58,898 - modelscope - INFO - loss = 0.0109268530586794972023-03-28 08:04:58,898 - modelscope - INFO - 5.595436483449031 instances per second; 126528 total (5.2352501867064975e-06 learn rate)2023-03-28 08:05:34,131 - modelscope - INFO - loss point 185 = 0.0076169923702934442023-03-28 08:07:36,629 - modelscope - INFO - loss point 186 = 0.0151611786602291412023-03-28 08:09:40,166 - modelscope - INFO - loss point 187 = 0.0167009712114211572023-03-28 08:10:09,798 - modelscope - INFO - ==========================================2023-03-28 08:10:09,799 - modelscope - INFO - loss = 0.0123330379135685372023-03-28 08:10:09,799 - modelscope - INFO - 5.59492928938975 instances per second; 128256 total (5.033607169529499e-06 learn rate)2023-03-28 08:11:42,957 - modelscope - INFO - loss point 188 = 0.0241983398708745842023-03-28 08:13:42,978 - modelscope - INFO - loss point 189 = 0.0139728084640892342023-03-28 08:15:14,159 - modelscope - INFO - ==========================================2023-03-28 08:15:14,160 - modelscope - INFO - loss = 0.0123210775793410142023-03-28 08:15:14,160 - modelscope - INFO - 5.596010795192408 instances per second; 129984 total (4.831964152352502e-06 learn rate)2023-03-28 08:15:43,621 - modelscope - INFO - loss point 190 = 0.0080980381430678132023-03-28 08:16:04,468 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328/_182023-03-28 08:16:07,608 - modelscope - INFO - epoch: 18 	 total_loss: 0.17743105641560192 	 2023-03-28 08:16:15,233 - modelscope - INFO - {'R@1': 0.91, 'R@2': 0.97, 'R@3': 0.98, 'R@5': 0.99}2023-03-28 08:16:15,235 - modelscope - INFO - meters is {'R@1': 0.91}2023-03-28 08:17:56,137 - modelscope - INFO - loss point 191 = 0.0084102987708892472023-03-28 08:19:56,093 - modelscope - INFO - loss point 192 = 0.01006795972285092023-03-28 08:20:19,203 - modelscope - INFO - ==========================================2023-03-28 08:20:19,203 - modelscope - INFO - loss = 0.0117661192806460862023-03-28 08:20:19,203 - modelscope - INFO - 5.594182396057938 instances per second; 131648 total (4.637789395070949e-06 learn rate)2023-03-28 08:21:58,600 - modelscope - INFO - loss point 193 = 0.00550802972538534062023-03-28 08:23:57,805 - modelscope - INFO - loss point 194 = 0.0049075261073224692023-03-28 08:25:23,156 - modelscope - INFO - ==========================================2023-03-28 08:25:23,156 - modelscope - INFO - loss = 0.0105097650119248662023-03-28 08:25:23,156 - modelscope - INFO - 5.5953416048507405 instances per second; 133376 total (4.4361463778939515e-06 learn rate)2023-03-28 08:25:58,582 - modelscope - INFO - loss point 195 = 0.0048545627306934152023-03-28 08:28:01,205 - modelscope - INFO - loss point 196 = 0.00372683287430731952023-03-28 08:30:03,214 - modelscope - INFO - loss point 197 = 0.00267556566563853652023-03-28 08:30:30,093 - modelscope - INFO - ==========================================2023-03-28 08:30:30,093 - modelscope - INFO - loss = 0.0091882019970338652023-03-28 08:30:30,093 - modelscope - INFO - 5.59577996379098 instances per second; 135104 total (4.2345033607169534e-06 learn rate)2023-03-28 08:32:04,401 - modelscope - INFO - loss point 198 = 0.0115886080404705372023-03-28 08:34:04,295 - modelscope - INFO - loss point 199 = 0.012872824436053342023-03-28 08:35:38,425 - modelscope - INFO - ==========================================2023-03-28 08:35:38,425 - modelscope - INFO - loss = 0.0096794875826682112023-03-28 08:35:38,425 - modelscope - INFO - 5.595888027686654 instances per second; 136832 total (4.032860343539955e-06 learn rate)2023-03-28 08:36:08,704 - modelscope - INFO - loss point 200 = 0.0097875475355918482023-03-28 08:36:31,522 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328/_192023-03-28 08:36:34,709 - modelscope - INFO - epoch: 19 	 total_loss: 0.16892224853804083 	 2023-03-28 08:36:42,374 - modelscope - INFO - {'R@1': 0.91, 'R@2': 0.96, 'R@3': 0.98, 'R@5': 0.99}2023-03-28 08:36:42,376 - modelscope - INFO - meters is {'R@1': 0.91}2023-03-28 08:38:22,762 - modelscope - INFO - loss point 201 = 0.0078442964021343732023-03-28 08:40:24,580 - modelscope - INFO - loss point 202 = 0.0044056180623682092023-03-28 08:40:45,938 - modelscope - INFO - ==========================================2023-03-28 08:40:45,938 - modelscope - INFO - loss = 0.0088936140097943282023-03-28 08:40:45,938 - modelscope - INFO - 5.5935936167229485 instances per second; 138496 total (3.838685586258402e-06 learn rate)2023-03-28 08:42:24,695 - modelscope - INFO - loss point 203 = 0.0137022462173784532023-03-28 08:44:29,087 - modelscope - INFO - loss point 204 = 0.007099744376789592023-03-28 08:45:54,438 - modelscope - INFO - ==========================================2023-03-28 08:45:54,438 - modelscope - INFO - loss = 0.0096124819635010772023-03-28 08:45:54,438 - modelscope - INFO - 5.59368843593429 instances per second; 140224 total (3.6370425690814043e-06 learn rate)2023-03-28 08:46:28,686 - modelscope - INFO - loss point 205 = 0.0090024488418465312023-03-28 08:48:30,218 - modelscope - INFO - loss point 206 = 0.0102014962313310492023-03-28 08:50:31,995 - modelscope - INFO - loss point 207 = 0.005186499156872642023-03-28 08:50:59,813 - modelscope - INFO - ==========================================2023-03-28 08:50:59,813 - modelscope - INFO - loss = 0.0087644530365360892023-03-28 08:50:59,813 - modelscope - INFO - 5.594469822806786 instances per second; 141952 total (3.4353995519044066e-06 learn rate)2023-03-28 08:52:33,807 - modelscope - INFO - loss point 208 = 0.0070803976284519232023-03-28 08:54:33,955 - modelscope - INFO - loss point 209 = 0.0132744214361472572023-03-28 08:56:07,298 - modelscope - INFO - ==========================================2023-03-28 08:56:07,298 - modelscope - INFO - loss = 0.0089306056962518522023-03-28 08:56:07,298 - modelscope - INFO - 5.594773017755218 instances per second; 143680 total (3.2337565347274085e-06 learn rate)2023-03-28 08:56:36,045 - modelscope - INFO - loss point 210 = 0.0180892609555287562023-03-28 08:56:58,061 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328/_202023-03-28 08:57:02,188 - modelscope - INFO - epoch: 20 	 total_loss: 0.16134210890546644 	 2023-03-28 08:57:10,056 - modelscope - INFO - {'R@1': 0.91, 'R@2': 0.95, 'R@3': 0.98, 'R@5': 0.99}2023-03-28 08:57:10,059 - modelscope - INFO - meters is {'R@1': 0.91}2023-03-28 08:58:49,830 - modelscope - INFO - loss point 211 = 0.0126806556860786442023-03-28 09:00:53,286 - modelscope - INFO - loss point 212 = 0.0095888367756484272023-03-28 09:01:14,807 - modelscope - INFO - ==========================================2023-03-28 09:01:14,807 - modelscope - INFO - loss = 0.0095104441835472782023-03-28 09:01:14,807 - modelscope - INFO - 5.592601145891916 instances per second; 145344 total (3.0395817774458552e-06 learn rate)2023-03-28 09:02:53,250 - modelscope - INFO - loss point 213 = 0.0067773099606247452023-03-28 09:04:56,902 - modelscope - INFO - loss point 214 = 0.0119325888458399752023-03-28 09:06:22,047 - modelscope - INFO - ==========================================2023-03-28 09:06:22,047 - modelscope - INFO - loss = 0.009390142832281362023-03-28 09:06:22,047 - modelscope - INFO - 5.5929710754090936 instances per second; 147072 total (2.8379387602688575e-06 learn rate)2023-03-28 09:06:57,795 - modelscope - INFO - loss point 215 = 0.0060376025432091422023-03-28 09:08:57,848 - modelscope - INFO - loss point 216 = 0.00327356116855974852023-03-28 09:10:58,370 - modelscope - INFO - loss point 217 = 0.0045103979045862432023-03-28 09:11:25,137 - modelscope - INFO - ==========================================2023-03-28 09:11:25,137 - modelscope - INFO - loss = 0.0085595353928645342023-03-28 09:11:25,137 - modelscope - INFO - 5.594205283620761 instances per second; 148800 total (2.6362957430918594e-06 learn rate)2023-03-28 09:13:00,093 - modelscope - INFO - loss point 218 = 0.0084987084464905932023-03-28 09:15:01,218 - modelscope - INFO - loss point 219 = 0.0109282626277516362023-03-28 09:16:31,751 - modelscope - INFO - ==========================================2023-03-28 09:16:31,752 - modelscope - INFO - loss = 0.008756954322364852023-03-28 09:16:31,752 - modelscope - INFO - 5.594678538898231 instances per second; 150528 total (2.4346527259148617e-06 learn rate)2023-03-28 09:17:02,147 - modelscope - INFO - loss point 220 = 0.0066832497606170842023-03-28 09:17:25,917 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328/_212023-03-28 09:17:29,188 - modelscope - INFO - epoch: 21 	 total_loss: 0.15432139226737634 	 2023-03-28 09:17:36,916 - modelscope - INFO - {'R@1': 0.91, 'R@2': 0.95, 'R@3': 0.98, 'R@5': 0.99}2023-03-28 09:17:36,918 - modelscope - INFO - meters is {'R@1': 0.91}2023-03-28 09:19:14,981 - modelscope - INFO - loss point 221 = 0.0063610821090576642023-03-28 09:21:17,896 - modelscope - INFO - loss point 222 = 0.0044710292394922432023-03-28 09:21:38,955 - modelscope - INFO - ==========================================2023-03-28 09:21:38,955 - modelscope - INFO - loss = 0.0079262494315681532023-03-28 09:21:38,955 - modelscope - INFO - 5.592668312264447 instances per second; 152192 total (2.2404779686333084e-06 learn rate)2023-03-28 09:23:15,614 - modelscope - INFO - loss point 223 = 0.0084241443127180922023-03-28 09:25:18,599 - modelscope - INFO - loss point 224 = 0.0051699903966582422023-03-28 09:26:43,593 - modelscope - INFO - ==========================================2023-03-28 09:26:43,593 - modelscope - INFO - loss = 0.0078098317645918372023-03-28 09:26:43,593 - modelscope - INFO - 5.593549936020183 instances per second; 153920 total (2.0388349514563107e-06 learn rate)2023-03-28 09:27:21,662 - modelscope - INFO - loss point 225 = 0.0053393281692453462023-03-28 09:29:24,790 - modelscope - INFO - loss point 226 = 0.010863732324827892023-03-28 09:31:24,604 - modelscope - INFO - loss point 227 = 0.0105859604657187052023-03-28 09:31:50,411 - modelscope - INFO - ==========================================2023-03-28 09:31:50,411 - modelscope - INFO - loss = 0.0082638520152452192023-03-28 09:31:50,412 - modelscope - INFO - 5.593973907318113 instances per second; 155648 total (1.8371919342793133e-06 learn rate)2023-03-28 09:33:25,144 - modelscope - INFO - loss point 228 = 0.0105645758762445442023-03-28 09:35:26,062 - modelscope - INFO - loss point 229 = 0.0078356022145091022023-03-28 09:36:57,170 - modelscope - INFO - ==========================================2023-03-28 09:36:57,170 - modelscope - INFO - loss = 0.0079471128849928772023-03-28 09:36:57,170 - modelscope - INFO - 5.594400451988242 instances per second; 157376 total (1.6355489171023154e-06 learn rate)2023-03-28 09:37:29,615 - modelscope - INFO - loss point 230 = 0.0067365512115545472023-03-28 09:37:53,614 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328/_222023-03-28 09:37:57,140 - modelscope - INFO - epoch: 22 	 total_loss: 0.14791883211682463 	 2023-03-28 09:38:04,799 - modelscope - INFO - {'R@1': 0.91, 'R@2': 0.96, 'R@3': 0.98, 'R@5': 0.99}2023-03-28 09:38:04,801 - modelscope - INFO - meters is {'R@1': 0.91}2023-03-28 09:39:42,548 - modelscope - INFO - loss point 231 = 0.0082371809600290482023-03-28 09:41:42,153 - modelscope - INFO - loss point 232 = 0.0071683027467150982023-03-28 09:42:03,239 - modelscope - INFO - ==========================================2023-03-28 09:42:03,239 - modelscope - INFO - loss = 0.0078409199590968542023-03-28 09:42:03,240 - modelscope - INFO - 5.5927029058259965 instances per second; 159040 total (1.441374159820762e-06 learn rate)2023-03-28 09:43:44,108 - modelscope - INFO - loss point 233 = 0.00555757984173126452023-03-28 09:45:46,256 - modelscope - INFO - loss point 234 = 0.0039430084935189792023-03-28 09:47:10,430 - modelscope - INFO - ==========================================2023-03-28 09:47:10,431 - modelscope - INFO - loss = 0.0069828013978872232023-03-28 09:47:10,431 - modelscope - INFO - 5.593049813575944 instances per second; 160768 total (1.2397311426437642e-06 learn rate)2023-03-28 09:47:47,497 - modelscope - INFO - loss point 235 = 0.00210232441014850462023-03-28 09:49:49,258 - modelscope - INFO - loss point 236 = 0.0011796035552472682023-03-28 09:51:50,209 - modelscope - INFO - loss point 237 = 0.0022920691694812023-03-28 09:52:17,735 - modelscope - INFO - ==========================================2023-03-28 09:52:17,736 - modelscope - INFO - loss = 0.0061150068924442412023-03-28 09:52:17,736 - modelscope - INFO - 5.593367402853095 instances per second; 162496 total (1.0380881254667663e-06 learn rate)2023-03-28 09:53:51,808 - modelscope - INFO - loss point 238 = 0.013113941586577562023-03-28 09:55:52,115 - modelscope - INFO - loss point 239 = 0.0087752086475807442023-03-28 09:57:23,997 - modelscope - INFO - ==========================================2023-03-28 09:57:23,997 - modelscope - INFO - loss = 0.0067804347333135572023-03-28 09:57:23,998 - modelscope - INFO - 5.593877172623989 instances per second; 164224 total (8.364451082897686e-07 learn rate)2023-03-28 09:57:55,027 - modelscope - INFO - loss point 240 = 0.0066094045746272022023-03-28 09:58:21,244 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328/_232023-03-28 09:58:24,689 - modelscope - INFO - epoch: 23 	 total_loss: 0.1419921316495656 	 2023-03-28 09:58:32,301 - modelscope - INFO - {'R@1': 0.9, 'R@2': 0.95, 'R@3': 0.98, 'R@5': 0.99}2023-03-28 09:58:32,303 - modelscope - INFO - meters is {'R@1': 0.9}2023-03-28 10:00:08,020 - modelscope - INFO - loss point 241 = 0.0033592928090321082023-03-28 10:02:10,985 - modelscope - INFO - loss point 242 = 0.0074461559019787772023-03-28 10:02:31,628 - modelscope - INFO - ==========================================2023-03-28 10:02:31,628 - modelscope - INFO - loss = 0.00675368535431186262023-03-28 10:02:31,628 - modelscope - INFO - 5.591960839820131 instances per second; 165888 total (6.422703510082152e-07 learn rate)2023-03-28 10:04:13,728 - modelscope - INFO - loss point 243 = 0.0047170158654726622023-03-28 10:06:15,539 - modelscope - INFO - loss point 244 = 0.0037386276373439382023-03-28 10:07:42,388 - modelscope - INFO - ==========================================2023-03-28 10:07:42,388 - modelscope - INFO - loss = 0.0060165539679253382023-03-28 10:07:42,388 - modelscope - INFO - 5.591635383706834 instances per second; 167616 total (4.4062733383121737e-07 learn rate)2023-03-28 10:08:19,337 - modelscope - INFO - loss point 245 = 0.0091518150511585882023-03-28 10:10:19,745 - modelscope - INFO - loss point 246 = 0.00717029449264767852023-03-28 10:12:19,702 - modelscope - INFO - loss point 247 = 0.0043062103012874062023-03-28 10:12:45,703 - modelscope - INFO - ==========================================2023-03-28 10:12:45,703 - modelscope - INFO - loss = 0.00618396119386787052023-03-28 10:12:45,704 - modelscope - INFO - 5.592691222595322 instances per second; 169344 total (2.389843166542196e-07 learn rate)2023-03-28 10:14:19,478 - modelscope - INFO - loss point 248 = 0.007313286594820912023-03-28 10:16:21,913 - modelscope - INFO - loss point 249 = 0.0087107675864492882023-03-28 10:17:49,528 - modelscope - INFO - ==========================================2023-03-28 10:17:49,528 - modelscope - INFO - loss = 0.0067478372270947992023-03-28 10:17:49,528 - modelscope - INFO - 5.593633012357244 instances per second; 171072 total (3.734129947722181e-08 learn rate)2023-03-28 10:18:22,924 - modelscope - INFO - loss point 250 = 0.0068601618357056482023-03-28 10:18:47,975 - modelscope - INFO - epoch: 24 	 total_loss: 0.1365667007085564 	 2023-03-28 10:18:55,670 - modelscope - INFO - {'R@1': 0.89, 'R@2': 0.96, 'R@3': 0.98, 'R@5': 0.99}2023-03-28 10:18:55,671 - modelscope - INFO - meters is {'R@1': 0.89}2023-03-28 10:18:55,672 - modelscope - INFO - loss_history = [2.9536031742165565, 2.2787040263135907, 1.7609239558785645, 1.4474030903574624, 1.2643667074353595, 1.0884581703684897, 0.9936811613296527, 0.9390945013866528, 0.8753589024212823, 0.8380325706790723, 0.7408956155050385, 0.7332096524114078, 0.6941102249351243, 0.65332297982604, 0.6104790429644805, 0.5963829326441337, 0.6027672546142218, 0.6044351289528027, 0.6472935555973494, 0.6136226714488808, 0.5334970583703781, 0.44768599743624293, 0.41302444141977346, 0.43584349840181286, 0.4343031675369685, 0.4066094188158761, 0.39847597413793795, 0.43652625683230545, 0.4320221041833552, 0.37940658833707236, 0.3067625204723964, 0.2930881526738735, 0.2914436087226662, 0.2694475968782157, 0.28660589224465344, 0.30618568614562847, 0.25786021754227334, 0.255057982833096, 0.2998185940946076, 0.28128503788416465, 0.23376274194417768, 0.1961637057496074, 0.1960117812467138, 0.16926058693257712, 0.17460459322511518, 0.19193413705174742, 0.19486783478203787, 0.20657955477530932, 0.21932730554737917, 0.18647412036992683, 0.171284277486029, 0.14223687112243114, 0.15089000163201355, 0.13332984001594828, 0.15381151477556443, 0.15523281782639603, 0.1476869189914756, 0.14114546026232708, 0.13954851461197731, 0.1344717296901661, 0.12369309277218189, 0.11738284949830874, 0.08677890147770162, 0.09049833123425373, 0.09377571408028713, 0.10089273086638341, 0.1170160488531736, 0.10335654184937292, 0.10899852955659844, 0.11186600685947791, 0.09080469580243718, 0.07680390874565671, 0.08557010284101339, 0.08289347628199585, 0.0784336292232899, 0.07687562360734455, 0.0852041506543511, 0.09434325065641579, 0.09840968540864065, 0.08760162562622247, 0.07445271420664794, 0.07357240266823906, 0.06375666773484089, 0.06507329555621671, 0.05478307395832054, 0.05524925718601881, 0.07095423478167955, 0.06827968457346617, 0.06637887587292746, 0.05958218743299756, 0.053460588108756445, 0.04200709053558748, 0.03691020253957442, 0.049214334025708815, 0.05716462226545559, 0.0593920294935479, 0.06764901731810344, 0.05554292153199212, 0.0412577046538013, 0.05554599217739168, 0.0523174308910253, 0.05337239339870101, 0.03774321001585433, 0.05322631998394765, 0.04249983173020093, 0.03039967079859295, 0.03429652693889183, 0.04381922393846771, 0.038655105439165977, 0.034717177780261704, 0.026250939615849664, 0.02411942141210054, 0.02041593609062558, 0.038135358297640906, 0.037032928098833885, 0.03979549061163222, 0.04085322735215853, 0.04429391729716239, 0.03781458346335844, 0.03150268436296168, 0.022524678960286263, 0.0247896655939297, 0.020721227078142838, 0.01978277047862912, 0.03135549330459047, 0.034632043697935544, 0.03263916652617448, 0.04111684956182663, 0.03991934762420358, 0.03254357383591063, 0.025787204218769587, 0.015528861855923233, 0.0284243678000519, 0.02190178212127846, 0.027919084287224238, 0.023483565605458022, 0.022732010808059967, 0.01978367043888872, 0.02068009534550553, 0.015039303566445233, 0.017919287961097128, 0.019143943315010327, 0.012683748537434418, 0.012528177136781777, 0.009236089953844975, 0.020217630930214232, 0.02053328472201367, 0.022875060922449533, 0.027224921771971774, 0.022347978145099947, 0.0182168328621718, 0.015121377778268334, 0.01677060345640999, 0.011112558149649152, 0.010241704685492115, 0.022927228380918867, 0.016256107014472828, 0.012020795937452802, 0.010219067092871684, 0.017796506084220842, 0.010467564171859215, 0.013684356457487378, 0.007565740494842438, 0.0065346331541155794, 0.012778960725603928, 0.017462116344301382, 0.02233379372156271, 0.01955543181899673, 0.011715369274361672, 0.01415085913907934, 0.013848264551566286, 0.007594965219732961, 0.007101105883325483, 0.009733313021438317, 0.006905896996698225, 0.0036477499663189242, 0.011244640808288452, 0.008848780099340902, 0.008305815677619066, 0.007918029010170536, 0.006823220346463623, 0.009297752352228556, 0.008758137683319052, 0.006634702161797781, 0.007616992370293444, 0.015161178660229141, 0.016700971211421157, 0.024198339870874584, 0.013972808464089234, 0.008098038143067813, 0.008410298770889247, 0.0100679597228509, 0.0055080297253853406, 0.004907526107322469, 0.004854562730693415, 0.0037268328743073195, 0.0026755656656385365, 0.011588608040470537, 0.01287282443605334, 0.009787547535591848, 0.007844296402134373, 0.004405618062368209, 0.013702246217378453, 0.00709974437678959, 0.009002448841846531, 0.010201496231331049, 0.00518649915687264, 0.007080397628451923, 0.013274421436147257, 0.018089260955528756, 0.012680655686078644, 0.009588836775648427, 0.006777309960624745, 0.011932588845839975, 0.006037602543209142, 0.0032735611685597485, 0.004510397904586243, 0.008498708446490593, 0.010928262627751636, 0.006683249760617084, 0.006361082109057664, 0.004471029239492243, 0.008424144312718092, 0.005169990396658242, 0.005339328169245346, 0.01086373232482789, 0.010585960465718705, 0.010564575876244544, 0.007835602214509102, 0.006736551211554547, 0.008237180960029048, 0.007168302746715098, 0.0055575798417312645, 0.003943008493518979, 0.0021023244101485046, 0.001179603555247268, 0.002292069169481, 0.01311394158657756, 0.008775208647580744, 0.006609404574627202, 0.003359292809032108, 0.007446155901978777, 0.004717015865472662, 0.003738627637343938, 0.009151815051158588, 0.0071702944926476785, 0.004306210301287406, 0.00731328659482091, 0.008710767586449288, 0.006860161835705648]2023-03-28 10:18:55,672 - modelscope - INFO - truncated to max length (512) 0 times2023-03-28 10:18:55,672 - modelscope - INFO - Saving model checkpoint to /root/autodl-tmp/output_rerank_choose_0328length of dataset is 6861 ori_joint